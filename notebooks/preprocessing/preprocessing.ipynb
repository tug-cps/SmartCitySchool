{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install pandas\n",
    "#!pip3 install seaborn\n",
    "#!pip3 install holidays\n",
    "#!pip3 install xgboost\n",
    "#!pip3 install holidays\n",
    "#!pip3 install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import holidays\n",
    "import datetime\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "color_pal = sns.color_palette()\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "holidays_AT = holidays.country_holidays('AT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the weather dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "graz_weather_df = pd.read_csv(\"../../data/graz_weather.csv\",delimiter=',',header=9,encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keeping only the relative weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['timestamp', 'Graz Temperature [2 m elevation corrected]',\n",
      "       'Graz Sunshine Duration', 'Graz Shortwave Radiation',\n",
      "       'Graz Direct Shortwave Radiation', 'Graz Diffuse Shortwave Radiation',\n",
      "       'Graz Precipitation Total', 'Graz Snowfall Amount',\n",
      "       'Graz Relative Humidity [2 m]', 'Graz Cloud Cover Total',\n",
      "       'Graz Wind Speed [10 m]', 'Graz Wind Direction [10 m]'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(graz_weather_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "graz_weather_df = graz_weather_df[['timestamp', 'Graz Temperature [2 m elevation corrected]','Graz Shortwave Radiation',\n",
    "'Graz Direct Shortwave Radiation', 'Graz Diffuse Shortwave Radiation','Graz Relative Humidity [2 m]']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the timestamp to the same format as that used in the energy datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_weather_timestamp(timestamp):\n",
    "    return(timestamp[6:8]+ '.' + timestamp[4:6] + '.' + timestamp[2:4] + ' ' + timestamp[9:11] + ':' + timestamp[11:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "graz_weather_df['timestamp'] = graz_weather_df['timestamp'].apply(parse_weather_timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the Energy Usage datasets and combining them into 1 dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coloumn names english translation:\n",
    "electricity_usage = 'electricity_usage'\n",
    "fbh_kalte = 'fbh_kalte'\n",
    "fbh_warme = 'fbh_warme'\n",
    "fernwarme = 'district_heating'\n",
    "warm_wasser = 'water_heating'\n",
    "luftung_kalte = 'vent_cooling'\n",
    "luftung_warme = 'vent_heating'\n",
    "pv = 'pv_production'\n",
    "turnsaal_warme = 'gym_heating'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "electricity_usage_df = pd.read_csv(\"../../data/WAAGNER-BIRO-STRASSE-99--8020-GRAZ-VSLEOPOLDINUM_Wertebericht_220801091637.csv\",delimiter=';',names=['timestamp',electricity_usage,'',' '], skiprows=9,encoding='unicode_escape',on_bad_lines='skip')\n",
    "fbh_kalte_df = pd.read_csv(\"../../data/WKZFBHKälte_Wertebericht_220801091739.csv\",delimiter=';',names=['timestamp',fbh_kalte,'',' '], skiprows=9,encoding='unicode_escape',on_bad_lines='skip')\n",
    "fbh_warme_df = pd.read_csv(\"../../data/WKZFBHWärme_Wertebericht_220801091812.csv\",delimiter=';',names=['timestamp',fbh_warme,'',' '], skiprows=9,encoding='unicode_escape',on_bad_lines='skip')\n",
    "fernwarme_warme_df = pd.read_csv(\"../../data/WMZFernwärmeWärme_Wertebericht_220801091521.csv\",delimiter=';',names=['timestamp',fernwarme,'',' '], skiprows=9,encoding='unicode_escape',on_bad_lines='skip')\n",
    "warm_wasser_df = pd.read_csv(\"../../data/WMZWarmwasserWärme_Wertebericht_220801092011.csv\",delimiter=';',names=['timestamp',warm_wasser,'',' '], skiprows=9,encoding='unicode_escape',on_bad_lines='skip')\n",
    "luftung_kalte_df = pd.read_csv(\"../../data/WKZLüftungKälte_Wertebericht_220801091709.csv\",delimiter=';',names=['timestamp',luftung_kalte,'',' '], skiprows=9,encoding='unicode_escape',on_bad_lines='skip')\n",
    "luftung_warme_df = pd.read_csv(\"../../data/WKZLüftungWärme_Wertebericht_220801091924.csv\",delimiter=';',names=['timestamp',luftung_warme,'',' '], skiprows=9,encoding='unicode_escape',on_bad_lines='skip')\n",
    "pv_df = pd.read_csv(\"../../data/WAAGNER-BIRO-STRASSE-99--8020-GRAZ-VSLEOPOLDINUM-PV_Wertebericht_220801092034.csv\",delimiter=';',names=['timestamp',pv,'',' '], skiprows=9,encoding='unicode_escape',on_bad_lines='skip')\n",
    "turnsaal_warme_df = pd.read_csv(\"../../data/WMZTurnsaalWärme_Wertebericht_220801091948.csv\",delimiter=';',names=['timestamp',turnsaal_warme,'',' '], skiprows=9,encoding='unicode_escape',on_bad_lines='skip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping the last n=9 rows as they are not part of the dataset\n",
    "n = 9\n",
    "electricity_usage_df.drop(electricity_usage_df.tail(n).index, inplace = True)\n",
    "fbh_kalte_df.drop(fbh_kalte_df.tail(n).index, inplace = True)\n",
    "fbh_warme_df.drop(fbh_warme_df.tail(n).index, inplace = True)\n",
    "fernwarme_warme_df.drop(fernwarme_warme_df.tail(n).index, inplace = True)\n",
    "warm_wasser_df.drop(warm_wasser_df.tail(n).index, inplace = True)\n",
    "luftung_kalte_df.drop(luftung_kalte_df.tail(n).index, inplace = True)\n",
    "luftung_warme_df.drop(luftung_warme_df.tail(n).index, inplace = True)\n",
    "pv_df.drop(pv_df.tail(n).index, inplace = True)\n",
    "turnsaal_warme_df.drop(turnsaal_warme_df.tail(n).index, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing bad dataframe coloumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coloumn names english translation:\n",
    "electricity_usage = 'electricity_usage'\n",
    "fbh_kalte = 'fbh_kalte'\n",
    "fbh_warme = 'fbh_warme'\n",
    "fernwarme = 'district_heating'\n",
    "warm_wasser = 'water_heating'\n",
    "luftung_kalte = 'vent_cooling'\n",
    "luftung_warme = 'vent_heating'\n",
    "pv = 'pv_production'\n",
    "turnsaal_warme = 'gym_heating'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "electricity_usage_df = electricity_usage_df[['timestamp',electricity_usage]]\n",
    "fbh_kalte_df = fbh_kalte_df[['timestamp',fbh_kalte]]\n",
    "fbh_warme_df = fbh_warme_df[['timestamp',fbh_warme]]\n",
    "fernwarme_warme_df = fernwarme_warme_df[['timestamp',fernwarme]]\n",
    "warm_wasser_df = warm_wasser_df[['timestamp',warm_wasser]]\n",
    "luftung_kalte_df = luftung_kalte_df[['timestamp',luftung_kalte]]\n",
    "luftung_warme_df = luftung_warme_df[['timestamp',luftung_warme]]\n",
    "pv_df = pv_df[['timestamp',pv]]\n",
    "turnsaal_warme_df = turnsaal_warme_df[['timestamp',turnsaal_warme]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([])\n",
    "df['timestamp'] = electricity_usage_df['timestamp']\n",
    "df[electricity_usage] = pd.to_numeric(electricity_usage_df[electricity_usage].str.replace(',','.'))\n",
    "df[fbh_kalte] = pd.to_numeric(fbh_kalte_df[fbh_kalte].str.replace(',','.'))\n",
    "df[fbh_warme] = pd.to_numeric(fbh_warme_df[fbh_warme].str.replace(',','.'))\n",
    "df[fernwarme] = pd.to_numeric(fernwarme_warme_df[fernwarme].str.replace(',','.'))\n",
    "df[warm_wasser] = pd.to_numeric(warm_wasser_df[warm_wasser].str.replace(',','.'))\n",
    "df[luftung_kalte] = pd.to_numeric(luftung_kalte_df[luftung_kalte].str.replace(',','.'))\n",
    "df[luftung_warme] = pd.to_numeric(luftung_warme_df[luftung_warme].str.replace(',','.'))\n",
    "df[pv] = pd.to_numeric(pv_df[pv].str.replace(',','.'))\n",
    "df[turnsaal_warme] = pd.to_numeric(turnsaal_warme_df[turnsaal_warme].str.replace(',','.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "It might make sense to interpolate weather data such that we have a reading for every 15 mins same as the energy data\n",
    "a good source might be: https://www.numpyninja.com/post/interpolation-using-pandas \n",
    "'''\n",
    "\n",
    "df = pd.merge(df,graz_weather_df,how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The get_date() and get_time() functions defined below are used to convert the timestamp into more meaningful date and time objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date(date_and_time):\n",
    "    date_str = date_and_time.split(' ')[0]\n",
    "    date_split = date_str.split('.')\n",
    "    curr_date = date.fromisoformat('20'+date_split[2]+'-'+date_split[1]+'-'+date_split[0])\n",
    "    return curr_date\n",
    "\n",
    "def get_time(date_and_time):\n",
    "    time_str = date_and_time.split(' ')[1]\n",
    "    return time_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Na values\n",
    "Here we are dropping any row for which we do not have the data for all data. \n",
    "To keep more data records we should first identify which features we will use and only then remove any missing coloumns. \n",
    "Also, not sure if it makes sense to put this line after train/test split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we are dropping any row for which we do not have the data for all data\n",
    "#To keep more data records we should first identify which features we will use and only then remove any missing coloumns\n",
    "#Also, not sure if it makes sense to put this line after train/test split\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.set_index('timestamp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accounting for holidays annd weekends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timestamp_to_datetime(timestamp):\n",
    "    date_str = timestamp.split(' ')[0]\n",
    "    time_str = timestamp.split(' ')[1]\n",
    "    datetime_obj = datetime.datetime(int('20'+date_str.split('.')[2]), int(date_str.split('.')[1] ), int(date_str.split('.')[0]),int(time_str[:2]), int(time_str[-2:]))\n",
    "    return datetime_obj\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = df['timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['timestamp'] = df['timestamp'].apply(timestamp_to_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_is_schoolday(date_arg):\n",
    "    '''\n",
    "    arg: datetime object\n",
    "    returns 1: if it is a school day\n",
    "    returns 0: if date is either in the weekend, a public holiday or during school break in styria\n",
    "    '''\n",
    "    #initilising to bad dates\n",
    "    semester_break_start = datetime.date(1999,1,1)\n",
    "    semester_break_end = datetime.date(1999,1,1)\n",
    "    easter_start = datetime.date(1999,1,1)\n",
    "    easter_end = datetime.date(1999,1,1)\n",
    "    pentecost_start = datetime.date(1999,1,1)\n",
    "    pentecost_end = datetime.date(1999,1,1)\n",
    "    summer_start = datetime.date(1999,1,1)\n",
    "    summer_end = datetime.date(1999,1,1)\n",
    "    autumn_start = datetime.date(1999,1,1)\n",
    "    autumn_end = datetime.date(1999,1,1)\n",
    "    christmas_start = datetime.date(1999,1,1)\n",
    "    christmas_end = datetime.date(1999,1,1)\n",
    "\n",
    "    if date_arg.year == 2021:\n",
    "        semester_break_start = datetime.date(2021,2,15)\n",
    "        semester_break_end = datetime.date(2021,2,21)\n",
    "        easter_start = datetime.date(2021,3,27)\n",
    "        easter_end = datetime.date(2021,4,5)\n",
    "        pentecost_start = datetime.date(2021,5,22)\n",
    "        pentecost_end = datetime.date(2021,5,24)\n",
    "        summer_start = datetime.date(2021,7,10)\n",
    "        summer_end = datetime.date(2021,9,12)\n",
    "        autumn_start = datetime.date(2021,10,27)\n",
    "        autumn_end = datetime.date(2021,10,31)\n",
    "        christmas_start = datetime.date(2021,12,24)\n",
    "        christmas_end = datetime.date(2022,1,6)\n",
    "       \n",
    "    elif date_arg.year == 2022:\n",
    "        semester_break_start = datetime.date(2022,2,21)\n",
    "        semester_break_end = datetime.date(2022,2,21)\n",
    "        easter_start = datetime.date(2022,4,9)\n",
    "        easter_end = datetime.date(2022,4,18)\n",
    "        pentecost_start = datetime.date(2022,6,4)\n",
    "        pentecost_end = datetime.date(2022,6,6)\n",
    "        summer_start = datetime.date(2022,7,9)\n",
    "        summer_end = datetime.date(2022,9,11)\n",
    "        autumn_start = datetime.date(2022,10,27)\n",
    "        autumn_end = datetime.date(2022,10,31)\n",
    "        christmas_start = datetime.date(2022,12,24)\n",
    "        christmas_end = datetime.date(2023,1,7)\n",
    "\n",
    "    \n",
    "    if semester_break_start <= date_arg.date() <= semester_break_end:\n",
    "        return 0\n",
    "    elif easter_start <= date_arg.date() <= easter_end:\n",
    "        return 0\n",
    "    elif pentecost_start <= date_arg.date() <= pentecost_end:\n",
    "        return 0\n",
    "    elif summer_start <= date_arg.date() <=  summer_end:\n",
    "        return 0\n",
    "    elif autumn_start <= date_arg.date() <= autumn_end:\n",
    "        return 0\n",
    "    elif christmas_start <= date_arg.date() <= christmas_end:\n",
    "        return 0\n",
    "    elif date_arg.date() in holidays_AT:\n",
    "        return 0\n",
    "    elif 5 <= date_arg.weekday() <= 6:\n",
    "        \n",
    "        return 0\n",
    "\n",
    "    else:\n",
    "        return 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_is_schoolday(datetime.datetime(2022,10,31))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_schoolday'] = df['timestamp'].apply(get_is_schoolday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['day'] = [x.day for x in df['timestamp']]\n",
    "df['month'] = [x.month for x in df['timestamp']]\n",
    "df['year'] = [x.year for x in df['timestamp']]\n",
    "df['hour'] = [x.hour for x in df['timestamp']]\n",
    "#minute not imp if we're sampling hourly\n",
    "#df['minute'] = [x.minute for x in df['timestamp']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../../data/energy_and_weather.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('scs': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e043919b94825cf8de930cbcec895040cfad3e5ea91d7ee03b07ea5a7f5b1ff3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
